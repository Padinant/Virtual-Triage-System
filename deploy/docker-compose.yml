services:
  postgres:
    image: postgres:14
    restart: unless-stopped
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
    volumes:
      - ./pg_data:/var/lib/postgresql/data

  n8n:
    image: n8nio/n8n    #:latest
    restart: unless-stopped
    depends_on:
      - postgres
    environment:
      - DB_TYPE=postgresdb
      - DB_POSTGRESDB_HOST=postgres
      - DB_POSTGRESDB_PORT=5432
      - DB_POSTGRESDB_DATABASE=${POSTGRES_DB}
      - DB_POSTGRESDB_USER=${POSTGRES_USER}
      - DB_POSTGRESDB_PASSWORD=${POSTGRES_PASSWORD}
      - N8N_HOST=${N8N_HOST}
      - N8N_PORT=${N8N_PORT}
      - N8N_PROTOCOL=${N8N_PROTOCOL}
      - GENERIC_TIMEZONE=${GENERIC_TIMEZONE}
      - N8N_ENCRYPTION_KEY=${N8N_ENCRYPTION_KEY}
    ports:
      - "5678:5678"
    volumes:
      - ./n8n_data:/home/node/.n8n

# NEW SECTION: OLLAMA
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    restart: unless-stopped
    ports: ["11434:11434"]
    volumes:
      - ollama:/root/.ollama

# pulls gemma3 1 billion parameter model - size: 815MB - this service is optional to run if you already have a model pulled 
# you can replace gemma3:1b with model code based on your needs
# terminal prompt to do this: docker exec -it ollama ollama pull gemma3:1b
  ollama-pull:
    image: ollama/ollama:latest
    depends_on: [ollama]
    entrypoint: ["/bin/sh","-lc",
      "sleep 15 && OLLAMA_HOST=http://ollama:11434 ollama pull gemma3:1b-instruct"
    ]
    restart: "no"

volumes:
  ollama:

